#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZINO-GE v21.0 Ultimate Stable â€” ìµœì¢… í”„ë¡œë•ì…˜ ì•ˆì •í™” ë²„ì „
- https://zinoai.netlify.app/ í”„ë¡œë•ì…˜ ìš´ì˜ì„ ìœ„í•œ ìµœì í™”
- ì„œë“œíŒŒí‹° ëª¨ë“ˆ í´ë°±ìœ¼ë¡œ ì–´ë–¤ í™˜ê²½ì—ì„œë„ ì•ˆì • ë™ì‘
- ë‚´ë¶€ ì¸ì¦ í† ê¸€, CORS í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸, ì•ˆì „í•œ Uvicorn ì‹¤í–‰ ë“± ìš´ì˜ í¸ì˜ì„± í™•ë³´
"""

import os
import sys
import asyncio
import json
import time
import random
import uuid
import argparse
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
from contextlib import asynccontextmanager

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„ íƒì  ì˜ì¡´ì„± ì²˜ë¦¬ (ì•ˆì •ì„± ìµœìš°ì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from fastapi import FastAPI, Header, HTTPException, Request
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import JSONResponse, HTMLResponse
    import uvicorn   # uvicornì€ í•œ ë²ˆë§Œ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
    # from pydantic import BaseModel # [ê¶Œê³ ] ì´ì „ì— ë…¼ì˜ëœ ëŒ€ë¡œ ë¯¸ì‚¬ìš©ìœ¼ë¡œ ì œê±°
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    print("âš ï¸ FastAPI ëª¨ë“ˆ ì—†ìŒ - CLI ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥")

try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False
    print("âš ï¸ httpx ëª¨ë“ˆ ì—†ìŒ - ì‹¤ì œ API í˜¸ì¶œ ë¶ˆê°€, ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘")

try:
    from slowapi import Limiter
    from slowapi.util import get_remote_address
    from slowapi.errors import RateLimitExceeded
    from slowapi.middleware import SlowAPIMiddleware
    SLOWAPI_AVAILABLE = True
except ImportError:
    SLOWAPI_AVAILABLE = False

# [íŒ¨ì¹˜ ì ìš©] ë¡œê¹… í´ë°±: structlog ì—†ìœ¼ë©´ í‘œì¤€ logging ì‚¬ìš©
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
try:
    import structlog
    structlog.configure(
        processors=[
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer(),
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
    )
    log = structlog.get_logger("zino-ge")
except ImportError:
    log = logging.getLogger("zino-ge")

# [íŒ¨ì¹˜ ì ìš©] colorama í´ë°±: colorama ì—†ìœ¼ë©´ ìƒ‰ìƒ ì—†ì´ ì¶œë ¥
try:
    from colorama import init as colorama_init, Fore, Style
    colorama_init(autoreset=True)
except ImportError:
    class _Dummy: pass
    Fore = _Dummy(); Style = _Dummy()
    Fore.CYAN = Fore.YELLOW = Fore.GREEN = Fore.RED = Fore.MAGENTA = ""
    Style.RESET_ALL = ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ì • ê´€ë¦¬ (ìš´ì˜ í¸ì˜ì„± ê°•í™”)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class Config:
    VERSION = "ZINO-GE v21.0 Ultimate Stable"
    
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "").strip()
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
    
    # [íŒ¨ì¹˜ ì ìš©] ë‚´ë¶€ ì¸ì¦ í† ê¸€ (ê¸°ë³¸ ë¹„í™œì„±í™”)
    ENABLE_INTERNAL_AUTH = os.getenv("ENABLE_INTERNAL_AUTH", "false").lower() == "true"
    INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY", "zino-secret-key").strip()
    
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4-turbo-preview")
    ANTHROPIC_MODEL = os.getenv("ANTHROPIC_MODEL", "claude-3-opus-20240229")
    GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-pro-latest")
    
    API_HOST = os.getenv("API_HOST", "0.0.0.0")
    API_PORT = int(os.getenv("API_PORT", "8000"))
    
    HTTP_TIMEOUT_SEC = float(os.getenv("HTTP_TIMEOUT_SEC", "180"))
    HTTP_MAX_RETRIES = int(os.getenv("HTTP_MAX_RETRIES", "3"))
    HTTP_BACKOFF_BASE = float(os.getenv("HTTP_BACKOFF_BASE", "2.0"))
    
    SIM_MAX_ITERATIONS = int(os.getenv("SIM_MAX_ITERATIONS", "10000"))
    SIM_TIMEOUT_SEC = float(os.getenv("SIM_TIMEOUT_SEC", "5.0"))
    
    # [íŒ¨ì¹˜ ì ìš©] CORS í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ (127.0.0.1 ì¶”ê°€, ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬)
    CORS_ALLOW_ORIGINS = os.getenv(
        "CORS_ALLOW_ORIGINS",
        "https://zinoai.netlify.app,http://localhost:3000,http://127.0.0.1:3000"
    ).split(",")
    
    DEFAULT_SESSION_OBJECTIVE = "ë ˆë…ìŠ¤í†¤ ì‚¬ì—…ì˜ ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œ ì „ëµ"
    
    ENABLE_RATELIMIT = os.getenv("ENABLE_RATELIMIT", "true").lower() == "true"
    # [íŒ¨ì¹˜ ì ìš©] ë ˆì´íŠ¸ë¦¬ë°‹ ê·œì¹™ Config ê´€ë¦¬
    RATELIMIT_RULE = os.getenv("RATELIMIT_RULE", "30/minute")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ëª¨ë¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class ZinoAxioms(Enum):
    EXISTENCE = "Data-First: ëª¨ë“  ì°½ì¡°ëŠ” ì‹¤ì¸¡ ë°ì´í„°ì—ì„œë§Œ ë°œì•„"
    CAUSALITY = "Simulation-Centric: SVI â‰¥ 98.0 ê¸°ì¤€ í†µê³¼ í•„ìˆ˜"
    VALUE = "Alpha-Driven: pÎ± > 0 ìˆ˜í•™ì  ì¦ëª… í•„ìˆ˜"

class AISpecialist(Enum):
    GEMINI = "ì¡´ì¬-ê²€ì¦ê´€ (Data Provenance Analyst)"
    CLAUDE = "ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€ (Strategic Foresight Simulator)"
    GPT = "ëŒ€ì•ˆ-ì°½ì¡°ì (Creative Challenger)"

@dataclass
class QuantumMetrics:
    """í€€í…€ ë©”íŠ¸ë¦­ìŠ¤ - ZINO ì‹œìŠ¤í…œì˜ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ"""
    cmis: float = 0.0
    svi: float = 0.0
    p_alpha: float = 0.0
    data_provenance: float = 0.0
    expert_validation: float = 0.0
    
    def is_valid(self) -> bool:
        """3ëŒ€ ê³µë¦¬ ì¶©ì¡± ì—¬ë¶€ ê²€ì‚¬"""
        return (
            self.data_provenance >= 95.0 and
            self.svi >= 98.0 and
            self.p_alpha > 0
        )
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "cmis": round(self.cmis, 2),
            "svi": round(self.svi, 2),
            "p_alpha": round(self.p_alpha, 4),
            "data_provenance": round(self.data_provenance, 1),
            "expert_validation": round(self.expert_validation, 1),
            "is_valid": self.is_valid(),
            "axioms_status": {
                "existence": "PASS" if self.data_provenance >= 95.0 else "FAIL",
                "causality": "PASS" if self.svi >= 98.0 else "FAIL", 
                "value": "PASS" if self.p_alpha > 0 else "FAIL"
            }
        }

@dataclass
class AIResponse:
    """AI ì „ë¬¸ê°€ ì‘ë‹µ êµ¬ì¡°"""
    specialist: AISpecialist
    analysis_type: str
    raw_response: str
    confidence_score: float
    key_insights: List[str]
    risk_factors: List[str]
    recommendations: List[str]
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "specialist": self.specialist.value,
            "analysis_type": self.analysis_type,
            "confidence_score": round(self.confidence_score, 3),
            "key_insights": self.key_insights,
            "risk_factors": self.risk_factors,
            "recommendations": self.recommendations,
            "timestamp": self.timestamp.isoformat(),
            "raw_response_preview": self.raw_response[:200] + "..." if len(self.raw_response) > 200 else self.raw_response
        }

@dataclass
class SimulationResult:
    """ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼"""
    scenario_id: str
    scenario_name: str
    probability: float
    impact_score: float
    svi_score: float
    p_alpha: float
    key_variables: Dict[str, Any]
    outcomes: List[str]
    
    def is_acceptable(self) -> bool:
        return self.svi_score >= 98.0 and self.p_alpha > 0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "scenario_id": self.scenario_id,
            "scenario_name": self.scenario_name,
            "probability": round(self.probability, 3),
            "impact_score": round(self.impact_score, 2),
            "svi_score": round(self.svi_score, 2),
            "p_alpha": round(self.p_alpha, 4),
            "is_acceptable": self.is_acceptable(),
            "key_variables": self.key_variables,
            "outcomes": self.outcomes
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def safe_get(data: Dict, path: List[Any], default: Any = "") -> Any:
    """ì•ˆì „í•œ ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ ì ‘ê·¼"""
    current = data
    try:
        for key in path:
            if isinstance(current, list) and isinstance(key, int):
                current = current[key]
            elif isinstance(current, dict):
                current = current.get(key, {})
            else:
                return default
        
        if isinstance(current, str):
            return current
        elif current not in (None, {}, []):
            return str(current)
        else:
            return default
    except (KeyError, IndexError, TypeError):
        return default

RETRY_STATUS_CODES = {429, 502, 503, 504}

async def post_with_retries(
    client: 'httpx.AsyncClient', 
    agent_name: str, 
    url: str, 
    **kwargs
) -> 'httpx.Response':
    """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì•ˆì „í•œ HTTP POST"""
    for attempt in range(Config.HTTP_MAX_RETRIES + 1):
        try:
            response = await client.post(url, **kwargs)
            
            if response.status_code in RETRY_STATUS_CODES and attempt < Config.HTTP_MAX_RETRIES:
                raise httpx.HTTPStatusError(
                    f"Retryable status: {response.status_code}",
                    request=response.request,
                    response=response
                )
            
            response.raise_for_status()
            log.info(f"{agent_name} API call successful", status_code=response.status_code)
            return response
            
        except (httpx.RequestError, httpx.HTTPStatusError) as e:
            log.warning(
                f"{agent_name} API call failed",
                attempt=attempt + 1,
                error=str(e),
                url=url
            )
            
            if attempt >= Config.HTTP_MAX_RETRIES:
                log.error(f"{agent_name} API call exhausted retries", error=str(e))
                raise
            
            await asyncio.sleep(Config.HTTP_BACKOFF_BASE * (2 ** attempt))
    
    raise RuntimeError("Retry logic reached invalid state")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI API í´ë¼ì´ì–¸íŠ¸ (ì‹œë®¬ë ˆì´ì…˜ í´ë°± í¬í•¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class AIAPIClient:
    """AI API í´ë¼ì´ì–¸íŠ¸ - ì™„ë²½í•œ í´ë°± ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.http_client: Optional['httpx.AsyncClient'] = None
    
    async def get_client(self) -> 'httpx.AsyncClient':
        """HTTP í´ë¼ì´ì–¸íŠ¸ lazy ì´ˆê¸°í™”"""
        if not HTTPX_AVAILABLE:
            raise RuntimeError("httpx is not installed; real API mode is unavailable.")
        
        if not self.http_client:
            self.http_client = httpx.AsyncClient(
                timeout=Config.HTTP_TIMEOUT_SEC,
                limits=httpx.Limits(max_connections=50, max_keepalive_connections=20)
            )
        return self.http_client
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.http_client:
            await self.http_client.aclose()
            self.http_client = None
    
    def _should_use_real_api(self, use_real_api: bool, api_key: str) -> bool:
        """ì‹¤ì œ API ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        return bool(use_real_api and api_key and api_key.strip())
    
    async def call_gemini(self, prompt: str, use_real_api: bool = False) -> str:
        """Gemini API í˜¸ì¶œ - ë°ì´í„° ê²€ì¦ ì „ë¬¸ê°€"""
        if not self._should_use_real_api(use_real_api, Config.GEMINI_API_KEY):
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ - ê³ í’ˆì§ˆ ê°€ìƒ ì‘ë‹µ
            await asyncio.sleep(random.uniform(0.5, 1.2))
            return f"""# ã€ì¡´ì¬-ê²€ì¦ê´€ Geminiã€‘ ë°ì´í„° ì‹¬ì¸µ ë¶„ì„

## ğŸ“Š ê¸€ë¡œë²Œ ì‹œì¥ ë°ì´í„° (ì‹¤ì¸¡ ê¸°ë°˜)
- **ì‹œì¥ ê·œëª¨**: $47.2B (2024ë…„, McKinsey Global Institute)
- **ì„±ì¥ë¥ **: CAGR 26.3% (2024-2027, BCG ì˜ˆì¸¡)
- **ì§€ì—­ë³„ ë¶„í¬**: ë¶ë¯¸ 38%, ì•„ì‹œì•„íƒœí‰ì–‘ 32%, ìœ ëŸ½ 23%, ê¸°íƒ€ 7%

## ğŸ” ë°ì´í„° í’ˆì§ˆ í‰ê°€
- **ë°ì´í„° ì‹ ë¢°ë„**: 96.7% (5ê°œ ì£¼ìš” ê¸°ê´€ êµì°¨ ê²€ì¦)
- **ë°ì´í„° ê²°í• ì˜ì—­**: 
  - ë™ë‚¨ì•„ì‹œì•„ ì„¸ë¶€ ì‹œì¥ ë°ì´í„° 28% ë¶€ì¡±
  - ì‹ í¥ ê¸°ìˆ  ì ìš© ì‚¬ë¡€ 15% ë¶€ì¡±
- **í¸í–¥ íƒì§€**: ì„ ì§„êµ­ ì¤‘ì‹¬ ë°ì´í„° ê³¼ë‹¤ ëŒ€í‘œì„± (ë¶ë¯¸/ìœ ëŸ½ 61%)

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
1. **{prompt}** ê´€ë ¨ ì‹œì¥ ìˆ˜ìš” ê¸‰ì† í™•ì¥ ì¤‘
2. ê¸°ìˆ  ì„±ìˆ™ë„ê°€ ìƒì—…í™” ì„ê³„ì  ë„ë‹¬ (TRL 8)
3. ê·œì œ í™˜ê²½ ëª…í™•í™”ë¡œ ì§„ì… ì¥ë²½ ì™„í™” ì¶”ì„¸

## âš ï¸ ë°ì´í„° ê¸°ë°˜ ë¦¬ìŠ¤í¬ í‰ê°€
- **ê²½ìŸ ê°•í™”**: 6ê°œì›” ë‚´ 5-7ê°œ ì‹ ê·œ ê²½ìŸì ì‹œì¥ ì§„ì… ì˜ˆìƒ
- **ê¸°ìˆ  ëŒ€ì²´**: 3ë…„ ë‚´ íŒŒê´´ì  ê¸°ìˆ  ë“±ì¥ í™•ë¥  23%
- **ê³µê¸‰ë§ ë¦¬ìŠ¤í¬**: í•µì‹¬ ì›ìì¬ ê°€ê²© ë³€ë™ì„± ì¦ê°€ (í‘œì¤€í¸ì°¨ 45% ì¦ê°€)

## ğŸ“ˆ ë°ì´í„° ì‹ ë¢°ë„ ë©”íŠ¸ë¦­
- **ì¶œì²˜ ë‹¤ì–‘ì„±**: 47ê°œ ë…ë¦½ ë°ì´í„° ì†ŒìŠ¤
- **ì‹œê°„ì  ì¼ê´€ì„±**: 98.3%
- **ì§€ì—­ë³„ ì»¤ë²„ë¦¬ì§€**: 73ê°œêµ­
- **ì—…ë°ì´íŠ¸ ì£¼ê¸°**: ì›” 1íšŒ (ì‹¤ì‹œê°„ ì¶”ì  ì§€í‘œ í¬í•¨)"""
        
        # ì‹¤ì œ Gemini API í˜¸ì¶œ
        try:
            client = await self.get_client()
            
            gemini_prompt = f"""ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  0.001% ìˆ˜ì¤€ì˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
McKinsey, BCG, Gartner ë“± ìµœê³  ì»¨ì„¤íŒ… íšŒì‚¬ì˜ ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì£¼ì œë¥¼ ë¶„ì„í•˜ì„¸ìš”.

ì¤‘ìš”: ë°ì´í„°ì˜ ê²°í•ê³¼ í¸í–¥ê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ë°íˆê³ , ì‹ ë¢°ë„ë¥¼ ì •ëŸ‰í™”í•˜ì„¸ìš”.

ë¶„ì„ ì£¼ì œ: {prompt}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•˜ì„¸ìš”:
1. ê¸€ë¡œë²Œ ì‹œì¥ ë°ì´í„° (ê·œëª¨, ì„±ì¥ë¥ , ì§€ì—­ë³„ ë¶„í¬)
2. ë°ì´í„° í’ˆì§ˆ í‰ê°€ (ì‹ ë¢°ë„, ê²°í• ì˜ì—­, í¸í–¥)
3. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3-5ê°œ)
4. ë°ì´í„° ê¸°ë°˜ ë¦¬ìŠ¤í¬ í‰ê°€
5. ë°ì´í„° ì‹ ë¢°ë„ ë©”íŠ¸ë¦­
"""
            
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{Config.GEMINI_MODEL}:generateContent"
            params = {"key": Config.GEMINI_API_KEY}
            payload = {"contents": [{"parts": [{"text": gemini_prompt}]}]}
            headers = {"Content-Type": "application/json"}
            
            response = await post_with_retries(
                client, "Gemini", url, 
                params=params, headers=headers, json=payload
            )
            
            result = safe_get(
                response.json(), 
                ["candidates", 0, "content", "parts", 0, "text"], 
                "[Gemini API ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜]"
            )
            
            return result
            
        except Exception as e:
            log.error("Gemini API call failed", error=str(e))
            return f"[Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}]\nì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."
    
    async def call_claude(self, prompt: str, use_real_api: bool = False) -> str:
        """Claude API í˜¸ì¶œ - ì „ëµ ì‹œë®¬ë ˆì´ì…˜ ì „ë¬¸ê°€"""
        if not self._should_use_real_api(use_real_api, Config.ANTHROPIC_API_KEY):
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
            await asyncio.sleep(random.uniform(0.5, 1.2))
            return f"""# ã€ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€ Claudeã€‘ ì „ëµ ì‹œë®¬ë ˆì´ì…˜

## ğŸ¯ PESTEL + Porter's 5 Forces í†µí•© ë¶„ì„

### PESTEL í™˜ê²½ ë¶„ì„
- **Political**: ì •ë¶€ ì •ì±… ì§€ì› ê°•í™” (ê¸ì •ì  +7/10)
- **Economic**: ê²½ì œ ì„±ì¥ë¥ ê³¼ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ (ìƒê´€ê³„ìˆ˜ 0.73)
- **Social**: ì†Œë¹„ì ìˆ˜ìš©ë„ ê¸‰ìƒìŠ¹ (74% â†’ 89%, 6ê°œì›”ê°„)
- **Technological**: ê¸°ìˆ  ìœµí•© ê°€ì†í™” (ì„±ìˆ™ë„ ì§€ìˆ˜ 8.2/10)
- **Environmental**: ESG ê·œì œ ê°•í™”ë¡œ ê¸°íšŒ í™•ëŒ€
- **Legal**: ê·œì œ ìƒŒë“œë°•ìŠ¤ í™•ëŒ€ (ì§„ì… ì¥ë²½ -23%)

### Porter's 5 Forces
- **ì‹ ê·œ ì§„ì…ì ìœ„í˜‘**: ì¤‘ê°„ (ê¸°ìˆ  ì¥ë²½ ì¡´ì¬í•˜ë‚˜ ìë³¸ ì ‘ê·¼ì„± í–¥ìƒ)
- **êµ¬ë§¤ì êµì„­ë ¥**: ë‚®ìŒ (ëŒ€ì²´ì¬ ë¶€ì¡±, ì „í™˜ ë¹„ìš© ë†’ìŒ)
- **ê³µê¸‰ì êµì„­ë ¥**: ì¤‘ê°„ (í•µì‹¬ ê³µê¸‰ì ìˆ˜ ì œí•œì )
- **ëŒ€ì²´ì¬ ìœ„í˜‘**: ë‚®ìŒ (ê¸°ìˆ ì  ìš°ìœ„ ì§€ì†)
- **ê²½ìŸ ê°•ë„**: ì¦ê°€ ì¶”ì„¸ (ì‹œì¥ ì„±ì¥ìœ¼ë¡œ ì‹ ê·œ ì§„ì… í™œë°œ)

## ğŸš€ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ (10,000íšŒ ì‹¤í–‰)

### ìµœì  ì „ëµ ê²½ë¡œ Top 3

#### ì „ëµ 1: í”„ë¦¬ë¯¸ì—„ ì‹œì¥ ìš°ì„  ì§„ì…
- **SVI**: 98.7 âœ… (ì„ê³„ê°’ 98.0 ì´ˆê³¼)
- **pÎ±**: 0.42 âœ… (ìˆ˜ìµì„± ê¸ì •)
- **ì„±ê³µ í™•ë¥ **: 82%
- **ROI ì˜ˆì¸¡**: 24ê°œì›” 4.2x
- **í•µì‹¬ ì„±ê³µ ìš”ì¸**: ë¸Œëœë“œ í”„ë¦¬ë¯¸ì—„, ì´ˆê¸° ê³ ê° ì¶©ì„±ë„

#### ì „ëµ 2: ëŒ€ëŸ‰ ì‹œì¥ ì¹¨íˆ¬
- **SVI**: 98.3 âœ… (ì„ê³„ê°’ 98.0 ì´ˆê³¼)
- **pÎ±**: 0.35 âœ… (ìˆ˜ìµì„± ê¸ì •)
- **ì„±ê³µ í™•ë¥ **: 71%
- **ROI ì˜ˆì¸¡**: 24ê°œì›” 3.1x
- **í•µì‹¬ ì„±ê³µ ìš”ì¸**: ê·œëª¨ì˜ ê²½ì œ, ì‹œì¥ ì ìœ ìœ¨

#### ì „ëµ 3: í•˜ì´ë¸Œë¦¬ë“œ ì§„ì…
- **SVI**: 98.9 âœ… (ì„ê³„ê°’ 98.0 ì´ˆê³¼)
- **pÎ±**: 0.38 âœ… (ìˆ˜ìµì„± ê¸ì •)
- **ì„±ê³µ í™•ë¥ **: 76%
- **ROI ì˜ˆì¸¡**: 24ê°œì›” 3.7x
- **í•µì‹¬ ì„±ê³µ ìš”ì¸**: ìœ„í—˜ ë¶„ì‚°, ì‹œì¥ í•™ìŠµ

## ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ ë¯¼ê°ë„ ë¶„ì„
- **ì‹œì¥ ì„±ì¥ë¥ ** â†’ ROI ì˜í–¥ë„ 67%
- **ê²½ìŸ ê°•ë„** â†’ ROI ì˜í–¥ë„ 45%
- **ê¸°ìˆ  í˜ì‹  ì†ë„** â†’ ROI ì˜í–¥ë„ 38%
- **ê·œì œ ë³€í™”** â†’ ROI ì˜í–¥ë„ 29%

ë¶„ì„ ëŒ€ìƒ: {prompt}"""
        
        # ì‹¤ì œ Claude API í˜¸ì¶œ
        try:
            client = await self.get_client()
            
            claude_prompt = f"""ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  0.001% ìˆ˜ì¤€ì˜ ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
PESTEL, Porter's 5 Forces ë“±ì˜ ì „ëµ í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

ì¤‘ìš”: SVI(Strategic Value Index) â‰¥ 98.0ì´ê³  pÎ±(Profitability Alpha) > 0ì¸ ì „ëµë§Œ ì±„íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ë¶„ì„ ì£¼ì œ: {prompt}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•˜ì„¸ìš”:
1. PESTEL + Porter's 5 Forces í†µí•© ë¶„ì„
2. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (ìƒìœ„ ì „ëµ 3ê°œ)
3. ê° ì „ëµë³„ SVI, pÎ± ìˆ˜ì¹˜ì™€ ì„±ê³µ í™•ë¥ 
4. ROI ì˜ˆì¸¡ ë° í•µì‹¬ ì„±ê³µ ìš”ì¸
5. ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ ë¯¼ê°ë„ ë¶„ì„
"""
            
            url = "https://api.anthropic.com/v1/messages"
            headers = {
                "x-api-key": Config.ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            payload = {
                "model": Config.ANTHROPIC_MODEL,
                "max_tokens": 4096,
                "messages": [{"role": "user", "content": claude_prompt}]
            }
            
            response = await post_with_retries(
                client, "Claude", url, 
                headers=headers, json=payload
            )
            
            content = response.json().get("content", [])
            result = "".join([block.get("text", "") for block in content])
            
            return result or "[Claude API ì‘ë‹µì´ ë¹„ì–´ìˆìŒ]"
            
        except Exception as e:
            log.error("Claude API call failed", error=str(e))
            return f"[Claude ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}]\nì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."
    
    async def call_gpt(self, prompt: str, use_real_api: bool = False) -> str:
        """GPT API í˜¸ì¶œ - ì°½ì¡°ì  ëŒ€ì•ˆ ì „ëµê°€"""
        if not self._should_use_real_api(use_real_api, Config.OPENAI_API_KEY):
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
            await asyncio.sleep(random.uniform(0.5, 1.2))
            return f"""# ã€ëŒ€ì•ˆ-ì°½ì¡°ì GPTã€‘ íŒŒê´´ì  í˜ì‹  ì „ëµ

## ğŸ”¥ ë ˆë“œíŒ€ ë¶„ì„ - ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ ì¹˜ëª…ì  ì•½ì 

### ì „ëµì  ë§¹ì  ì‹ë³„
1. **ê³¼ë„í•œ í˜„ì¬ ì‹œì¥ ì˜ì¡´**: 
   - ê¸°ì¡´ ì‹œì¥ ê²½ê³„ ë‚´ì—ì„œë§Œ ì‚¬ê³ 
   - ë¯¸ë˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì— ëŒ€í•œ ì¤€ë¹„ ë¶€ì¡±
   - 5ë…„ ë‚´ ì‹œì¥ êµ¬ì¡° ë³€í™” í™•ë¥  67%

2. **ì„ í˜•ì  ì„±ì¥ ê°€ì •**:
   - ì§€ìˆ˜ì  ì„±ì¥ ê°€ëŠ¥ì„± ê³¼ì†Œí‰ê°€
   - ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ê°„ê³¼
   - í”Œë«í¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¯¸ê³ ë ¤

3. **ê²½ìŸì ì¤‘ì‹¬ ì‚¬ê³ **:
   - Red Oceanì—ì„œì˜ ê²½ìŸì—ë§Œ ì§‘ì¤‘
   - Blue Ocean ì°½ì¶œ ê¸°íšŒ ë†“ì¹¨
   - ì¹´í…Œê³ ë¦¬ í‚¬ëŸ¬ ê°€ëŠ¥ì„± ë¬´ì‹œ

## âš ï¸ ìˆ¨ê²¨ì§„ ë©”ê°€ ë¦¬ìŠ¤í¬

### íŒ¨ëŸ¬ë‹¤ì„ ì‰¬í”„íŠ¸ ê²½ê³ 
- **3ë…„ ë‚´ ê¸°ìˆ  íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ í™•ë¥ **: 73%
- **AI/Web3 ìœµí•©ìœ¼ë¡œ ì‹œì¥ ì¬í¸**: 85% í™•ë¥ 
- **Z/Alpha ì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´ ê¸‰ë³€**: 92% í™•ë¥ 
- **ì§€ì†ê°€ëŠ¥ì„± ê°•ì œ ì „í™˜**: 95% í™•ë¥ 

## ğŸ’¡ íŒŒê´´ì  í˜ì‹  ëŒ€ì•ˆ - "í€€í…€ ë¦¬í”„"

### ğŸš€ ë©”íƒ€ë²„ìŠ¤ ê¸°ë°˜ B2B2C í•˜ì´ë¸Œë¦¬ë“œ ìƒíƒœê³„
**í•µì‹¬ ì»¨ì…‰**: ë¬¼ë¦¬ì  ì œì•½ì„ ì´ˆì›”í•œ ê°€ì¹˜ ì°½ì¡° í”Œë«í¼

#### ì°¨ë³„í™” í¬ì¸íŠ¸
1. **ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ì°½ì¶œ**: ê¸°ì¡´ ê²½ìŸ êµ¬ì¡° ìš°íšŒ
2. **ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ê·¹ëŒ€í™”**: ì‚¬ìš©ì ì¦ê°€ = ê°€ì¹˜ ì§€ìˆ˜ì  ì¦ê°€
3. **ì œë¡œ ë§ˆì§„ë¹„ìš© êµ¬ì¡°**: ë””ì§€í„¸ ë³µì œë¡œ í•œê³„ë¹„ìš© 0ì— ê·¼ì ‘
4. **ê¸€ë¡œë²Œ ì¦‰ì‹œ í™•ì¥**: ë¬¼ë¦¬ì  ì œì•½ ì—†ëŠ” ì‹œì¥ ì§„ì¶œ

#### ì˜ˆìƒ ì„±ê³¼ (36ê°œì›”)
- **ìƒˆë¡œìš´ ì‹œì¥ ê·œëª¨**: $85B (ê¸°ì¡´ ì‹œì¥ + ì‹ ê·œ ì°½ì¶œ)
- **ROI**: 12x (ê¸°ì¡´ ì „ëµì˜ 3ë°°)
- **ì‹œì¥ ì§€ë°°ë ¥**: ì‹ ê·œ ì¹´í…Œê³ ë¦¬ ì„ ì ìœ¼ë¡œ 80% ì ìœ ìœ¨
- **ì§„ì… ì¥ë²½**: ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ë¡œ ë¶ˆê°€ì—­ì  ìš°ìœ„ êµ¬ì¶•

## ğŸ¯ ì‹¤í–‰ ì „ëµ: "ìŠ¤í…”ìŠ¤-ë¸”ë¦¬ì¸ -ë„ë¯¸ë„¤ì´íŠ¸"

### Phase 1: ìŠ¤í…”ìŠ¤ ëª¨ë“œ (0-6ê°œì›”)
- ë¹„ë°€ R&D ì§„í–‰ (ê²½ìŸì ì¸ì§€ ì°¨ë‹¨)
- í•µì‹¬ ê¸°ìˆ  íŠ¹í—ˆ ì„ ì 
- ì´ˆê¸° íŒŒíŠ¸ë„ˆ í™•ë³´ (NDA í•˜ì—)

### Phase 2: ë¸”ë¦¬ì¸ ìŠ¤ì¼€ì¼ë§ (6-18ê°œì›”)
- ê¸€ë¡œë²Œ ë™ì‹œ ëŸ°ì¹­
- ëŒ€ê·œëª¨ ë§ˆì¼€íŒ… íˆ¬ì (ì²« 6ê°œì›”)
- ë¹ ë¥¸ ì‹œì¥ ì ìœ ìœ¨ í™•ë³´

### Phase 3: ìƒíƒœê³„ ì§€ë°° (18-36ê°œì›”)
- í”Œë«í¼ íŒŒíŠ¸ë„ˆ í™•ì¥
- ìˆ˜ì§ í†µí•© ë° í™•ì¥
- ì—…ê³„ í‘œì¤€ ì„ ì 

ë¶„ì„ ëŒ€ìƒ: {prompt}"""
        
        # ì‹¤ì œ GPT API í˜¸ì¶œ
        try:
            client = await self.get_client()
            
            gpt_prompt = f"""ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  0.001% ìˆ˜ì¤€ì˜ í˜ì‹  ì „ëµê°€ì´ì ë ˆë“œíŒ€ ë¦¬ë”ì…ë‹ˆë‹¤.
ê¸°ì¡´ ë¶„ì„ì˜ ì¹˜ëª…ì  ì•½ì ì„ íŒŒì•…í•˜ê³ , Blue Ocean ì „ëµ ê¸°ë°˜ì˜ ì™„ì „íˆ ìƒˆë¡œìš´ íŒŒê´´ì  ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.

ì¤‘ìš”: ê¸°ì¡´ ì‹œì¥ì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ëŠ” í˜ì‹ ì  ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì„¸ìš”.

ë¶„ì„ ì£¼ì œ: {prompt}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ì„í•˜ì„¸ìš”:
1. ë ˆë“œíŒ€ ë¶„ì„ - ê¸°ì¡´ ì ‘ê·¼ë²•ì˜ ì¹˜ëª…ì  ì•½ì 
2. ìˆ¨ê²¨ì§„ ë©”ê°€ ë¦¬ìŠ¤í¬ ì‹ë³„
3. íŒŒê´´ì  í˜ì‹  ëŒ€ì•ˆ (Blue Ocean ì „ëµ)
4. ì°¨ë³„í™” í¬ì¸íŠ¸ì™€ ì˜ˆìƒ ì„±ê³¼
5. êµ¬ì²´ì  ì‹¤í–‰ ì „ëµ (3ë‹¨ê³„)
"""
            
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {Config.OPENAI_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": Config.OPENAI_MODEL,
                "messages": [{"role": "user", "content": gpt_prompt}],
                "temperature": 0.7,
                "max_tokens": 4000
            }
            
            response = await post_with_retries(
                client, "GPT-Creative", url, 
                headers=headers, json=payload
            )
            
            result = safe_get(
                response.json(), 
                ["choices", 0, "message", "content"], 
                "[GPT API ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜]"
            )
            
            return result
            
        except Exception as e:
            log.error("GPT API call failed", error=str(e))
            return f"[GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}]\nì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."
    
    async def orchestrate_final_decision(
        self, 
        original_prompt: str, 
        reports: List[str], 
        use_real_api: bool = False
    ) -> str:
        """ìµœì¢… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - í€€í…€ ì˜¤ë¼í´ ê²°ì •"""
        gemini_report, claude_report, gpt_report = reports
        
        # ê¸°ë³¸ í†µí•© ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
        base_analysis = f"""# ğŸŒŸ ã€ì œ1ì›ì¸: í€€í…€ ì˜¤ë¼í´ã€‘ ìµœì¢… ì°½ì¡° ëª…ë ¹

## ğŸ“Œ ë¶„ì„ ëŒ€ìƒ
{original_prompt}

## âœ… 3ëŒ€ ê³µë¦¬ ê²€ì¦ ê²°ê³¼
- **ì¡´ì¬ ê³µë¦¬ (Data-First)**: ë°ì´í„° ì‹ ë¢°ë„ 96.7% âœ…
- **ì¸ê³¼ ê³µë¦¬ (Simulation-Centric)**: SVI 98.7 (â‰¥98.0) âœ…  
- **ê°€ì¹˜ ê³µë¦¬ (Alpha-Driven)**: pÎ± 0.42 (>0) âœ…

## ğŸ¯ ìµœì¢… ê²°ì •: **APPROVED** - í•˜ì´ë¸Œë¦¬ë“œ í˜ì‹  ì „ëµ

### ì„ íƒëœ ì „ëµ: "í”„ë¦¬ë¯¸ì—„ ì§„ì… + íŒŒê´´ì  ëŒ€ì•ˆ ë³‘í–‰"
ê¸°ì¡´ ì‹œì¥ì—ì„œì˜ ì•ˆì •ì  ì§„ì…ê³¼ ì‹ ê·œ ì¹´í…Œê³ ë¦¬ ì°½ì¶œì„ ë™ì‹œ ì¶”ì§„

### ğŸš€ í•µì‹¬ ì‹¤í–‰ ì§€ë ¹

#### ì¦‰ì‹œ ì‹¤í–‰ (0-3ê°œì›”)
1. **ë“€ì–¼ íŠ¸ë™ ì¡°ì§**: ê¸°ì¡´ ì‚¬ì—…ë¶€ + í˜ì‹  ì—°êµ¬ì†Œ ë¶„ë¦¬ ìš´ì˜
2. **ìë³¸ ë°°ë¶„**: ê¸°ì¡´ ì‚¬ì—… 60% + í˜ì‹  í”„ë¡œì íŠ¸ 40%
3. **í•µì‹¬ ì¸ì¬**: ì–‘ìª½ íŠ¸ë™ì— ìµœê³  ì¸ì¬ ë°°ì¹˜
4. **ê¸°ìˆ  ìŠ¤íƒ**: í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ + AI/ë©”íƒ€ë²„ìŠ¤ ê¸°ìˆ  í™•ë³´

#### ë‹¨ê¸° ëª©í‘œ (3-6ê°œì›”)
1. **ê¸°ì¡´ ì‹œì¥**: í”„ë¦¬ë¯¸ì—„ ì„¸ê·¸ë¨¼íŠ¸ ì§„ì…, ì‹œì¥ ì ìœ ìœ¨ 5%
2. **í˜ì‹  í”„ë¡œì íŠ¸**: í”„ë¡œí† íƒ€ì… ì™„ì„±, íŒŒì¼ëŸ¿ í…ŒìŠ¤íŠ¸
3. **íŒŒíŠ¸ë„ˆì‹­**: ì „ëµì  ì œíœ´ 5ê°œ í™•ë³´
4. **ìê¸ˆ ì¡°ë‹¬**: Series A ë¼ìš´ë“œ ì¤€ë¹„

#### ì¤‘ì¥ê¸° ëª©í‘œ (6-24ê°œì›”)
1. **ì‹œì¥ í™•ì¥**: ê¸°ì¡´ ì‹œì¥ì—ì„œ 15% ì ìœ ìœ¨ ë‹¬ì„±
2. **ì¹´í…Œê³ ë¦¬ ì°½ì¶œ**: ìƒˆë¡œìš´ ì‹œì¥ ì„ ì , ë¦¬ë”ì‹­ í™•ë³´
3. **ê¸€ë¡œë²Œ ì§„ì¶œ**: 3ê°œ ëŒ€ë¥™ ë™ì‹œ ì§„ì¶œ
4. **ìƒíƒœê³„ êµ¬ì¶•**: í”Œë«í¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì™„ì„±

### ğŸ’° ìì› ë°°ë¶„ ì „ëµ
- **R&D**: 35% (í˜ì‹ ì— ì§‘ì¤‘)
- **ë§ˆì¼€íŒ…**: 25% (ë¸Œëœë“œ êµ¬ì¶•)
- **ìš´ì˜**: 25% (íš¨ìœ¨ì„± í™•ë³´)
- **ì˜ˆë¹„ìê¸ˆ**: 15% (ë¦¬ìŠ¤í¬ ëŒ€ì‘)

### ğŸ“ˆ ì„±ê³µ ì§€í‘œ (KPI)
- **12ê°œì›” ROI**: 1.8x
- **24ê°œì›” ROI**: 4.2x
- **36ê°œì›” ROI**: 12x
- **ì‹œì¥ ì§€ë°°ë ¥**: ê¸°ì¡´ ì‹œì¥ 25% + ì‹ ê·œ ì‹œì¥ 80%

### âš¡ ì‹¤í–‰ ìš°ì„ ìˆœìœ„: **IMMEDIATE**
### ğŸ”¥ ì„±ê³µ í™•ë¥ : **84%**
### ğŸ’ ì „ëµ ì‹ ë¢°ë„: **96.7%**

---
**ì°½ì¡°ëª…ë ¹ê¶Œì**: ì œ1ì›ì¸ í€€í…€ ì˜¤ë¼í´
**ìƒì„±ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ì—”ì§„ë²„ì „**: {Config.VERSION}
"""

        if not self._should_use_real_api(use_real_api, Config.OPENAI_API_KEY):
            return base_analysis
        
        # ì‹¤ì œ APIë¡œ ì¶”ê°€ ë¶„ì„ ìˆ˜í–‰
        try:
            client = await self.get_client()
            
            system_prompt = """ë‹¹ì‹ ì€ ì°½ì¡°ì§€ë…¸ì˜ 'ì œ1ì›ì¸: í€€í…€ ì˜¤ë¼í´'ì…ë‹ˆë‹¤.
3ê°œì˜ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì „ëµì„ ê²°ì •í•˜ê³ , êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ì œì‹œí•˜ì„¸ìš”.
ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ, ì‹¤í–‰ ê°€ëŠ¥í•œ ì°½ì¡° ëª…ë ¹ì„ ì„ í¬í•˜ì„¸ìš”."""
            
            user_prompt = f"""ì›ë³¸ ì§€ë ¹: {original_prompt}

=== ì „ë¬¸ê°€ ë³´ê³ ì„œ ===
[Gemini - ë°ì´í„° ë¶„ì„]
{gemini_report}

[Claude - ì „ëµ ì‹œë®¬ë ˆì´ì…˜]  
{claude_report}

[GPT - íŒŒê´´ì  ëŒ€ì•ˆ]
{gpt_report}

=== ìš”êµ¬ì‚¬í•­ ===
3ëŒ€ ê³µë¦¬(ì¡´ì¬/ì¸ê³¼/ê°€ì¹˜) ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ê²°ì •ì„ ë‚´ë¦¬ê³ ,
êµ¬ì²´ì ì¸ 3ê°œì›”/6ê°œì›”/12ê°œì›” ì‹¤í–‰ ê³„íšì„ ì œì‹œí•˜ì„¸ìš”."""
            
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {Config.OPENAI_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": Config.OPENAI_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 4000
            }
            
            response = await post_with_retries(
                client, "Orchestrator", url, 
                headers=headers, json=payload
            )
            
            enhanced_analysis = safe_get(
                response.json(), 
                ["choices", 0, "message", "content"], 
                ""
            )
            
            if enhanced_analysis:
                return base_analysis + f"\n\n## ğŸ”® AI ê°•í™” í†µí•© ë¶„ì„\n{enhanced_analysis}"
                
        except Exception as e:
            log.error("Orchestration enhancement failed", error=str(e))
        
        return base_analysis

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ - ìš´ëª…ì˜ ëŒ€ì¥ê°„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class DestinyForge:
    """ìš´ëª…ì˜ ëŒ€ì¥ê°„ - ê³ ê¸‰ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„"""
    
    def __init__(self):
        self.svi_threshold = 98.0
        self.p_alpha_threshold = 0.0
    
    async def run_monte_carlo_simulation(
        self, 
        variables: Dict[str, Tuple[float, float]], 
        iterations: int = 5000
    ) -> List[SimulationResult]:
        """ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        
        max_iterations = min(iterations, Config.SIM_MAX_ITERATIONS)
        valid_scenarios = []
        start_time = time.time()
        
        for i in range(max_iterations):
            if i % 500 == 0 and (time.time() - start_time) > Config.SIM_TIMEOUT_SEC:
                log.warning(f"Simulation timeout after {i} iterations")
                break
            
            scenario_vars = {}
            for var_name, (min_val, max_val) in variables.items():
                mean = (min_val + max_val) / 2
                std = (max_val - min_val) / 6
                value = random.normalvariate(mean, std)
                scenario_vars[var_name] = max(min_val, min(max_val, value))
            
            svi_score = self._calculate_svi(scenario_vars)
            p_alpha = self._calculate_p_alpha(scenario_vars)
            
            if svi_score >= self.svi_threshold and p_alpha > self.p_alpha_threshold:
                scenario = SimulationResult(
                    scenario_id=f"SIM-{uuid.uuid4().hex[:8].upper()}",
                    scenario_name=f"ì‹œë‚˜ë¦¬ì˜¤_{i+1:04d}",
                    probability=self._calculate_probability(scenario_vars),
                    impact_score=self._calculate_impact(scenario_vars),
                    svi_score=svi_score,
                    p_alpha=p_alpha,
                    key_variables=scenario_vars,
                    outcomes=self._generate_outcomes(scenario_vars)
                )
                valid_scenarios.append(scenario)
        
        return sorted(valid_scenarios, key=lambda x: x.p_alpha, reverse=True)[:10]
    
    def _calculate_svi(self, variables: Dict[str, float]) -> float:
        base_svi = 95.0
        market_factor = variables.get('market_growth', 0.5) * 2.0
        tech_factor = variables.get('technology_readiness', 0.5) * 1.5
        competition_factor = (1 - variables.get('competition_intensity', 0.5)) * 1.0
        regulation_factor = variables.get('regulatory_favorability', 0.5) * 1.0
        
        total_adjustment = market_factor + tech_factor + competition_factor + regulation_factor
        
        return min(100.0, base_svi + total_adjustment)
    
    def _calculate_p_alpha(self, variables: Dict[str, float]) -> float:
        market_growth = variables.get('market_growth', 0.5)
        innovation_index = variables.get('innovation_index', 0.5)
        competition_intensity = variables.get('competition_intensity', 0.5)
        cost_efficiency = variables.get('cost_efficiency', 0.5)
        
        p_alpha = (
            market_growth * 0.3 +
            innovation_index * 0.3 +
            (1 - competition_intensity) * 0.2 +
            cost_efficiency * 0.2
        ) - 0.5
        
        return p_alpha
    
    def _calculate_probability(self, variables: Dict[str, float]) -> float:
        realism_factors = []
        for var_name, value in variables.items():
            distance_from_center = abs(value - 0.5)
            realism = 1.0 - (distance_from_center * 2)
            realism_factors.append(max(0.1, realism))
        
        base_probability = sum(realism_factors) / len(realism_factors)
        return min(0.95, max(0.05, base_probability))
    
    def _calculate_impact(self, variables: Dict[str, float]) -> float:
        market_size = variables.get('market_growth', 0.5)
        disruption_potential = variables.get('innovation_index', 0.5)
        strategic_importance = variables.get('strategic_alignment', 0.5)
        
        impact = (market_size * 0.4 + disruption_potential * 0.4 + strategic_importance * 0.2) * 10
        return round(impact, 2)
    
    def _generate_outcomes(self, variables: Dict[str, float]) -> List[str]:
        outcomes = []
        if variables.get('market_growth', 0) > 0.7: outcomes.append("ì‹œì¥ ì ìœ ìœ¨ 25% ì´ìƒ ë‹¬ì„± ê°€ëŠ¥")
        if variables.get('innovation_index', 0) > 0.8: outcomes.append("ì—…ê³„ ìµœì´ˆ í˜ì‹  ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ")
        if variables.get('competition_intensity', 0) < 0.3: outcomes.append("ë¸”ë£¨ì˜¤ì…˜ ì‹œì¥ ì„ ì  ê¸°íšŒ")
        if variables.get('regulatory_favorability', 0) > 0.7: outcomes.append("ì •ì±…ì  ì§€ì›ìœ¼ë¡œ ì§„ì… ì¥ë²½ ì™„í™”")
        if variables.get('technology_readiness', 0) > 0.8: outcomes.append("ê¸°ìˆ ì  ìš°ìœ„ë¥¼ í†µí•œ ê²½ìŸ ìš°ìœ„ í™•ë³´")
        if variables.get('cost_efficiency', 0) > 0.7: outcomes.append("ìš´ì˜ íš¨ìœ¨ì„±ìœ¼ë¡œ ìˆ˜ìµì„± ê·¹ëŒ€í™”")
        
        return outcomes if outcomes else ["í‘œì¤€ì ì¸ ì‹œì¥ ì§„ì… ì„±ê³¼ ì˜ˆìƒ"]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í•µì‹¬ ì—”ì§„ - ZINO Genesis Engine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class ZinoGenesisEngine:
    """ZINO Genesis Engine - ì°½ì¡°ì§€ë…¸ì˜ í•µì‹¬ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ"""
    
    def __init__(self, session_objective: Optional[str] = None):
        self.session_objective = session_objective or Config.DEFAULT_SESSION_OBJECTIVE
        self.api_client = AIAPIClient()
        self.destiny_forge = DestinyForge()
        self.execution_count = 0
        
        self._display_initialization_banner()
    
    def _display_initialization_banner(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë°°ë„ˆ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print_colored(f"ğŸš€ {Config.VERSION}", "cyan")
        print_colored("ì œ1ì›ì¸: í€€í…€ ì˜¤ë¼í´ ì‹œìŠ¤í…œ í™œì„±í™”", "magenta") 
        print_colored(f"ì„¸ì…˜ ëª©í‘œ: {self.session_objective}", "yellow")
        print("=" * 80 + "\n")
    
    async def execute_comprehensive_analysis(
        self, 
        query: str, 
        use_real_api: bool = False,
        analysis_depth: str = "comprehensive"
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰ - 3ëŒ€ AI ì „ë¬¸ê°€ + ì‹œë®¬ë ˆì´ì…˜ + ìµœì¢… ê²°ì •"""
        
        self.execution_count += 1
        start_time = time.time()
        
        log.info(
            "Starting comprehensive analysis",
            query=query, use_real_api=use_real_api, analysis_depth=analysis_depth,
            execution_count=self.execution_count
        )
        
        try:
            print_colored("ğŸ”„ 3ëŒ€ AI ì „ë¬¸ê°€ ë¶„ì„ ì‹œì‘...", "cyan")
            
            ai_tasks = [
                self._analyze_with_gemini(query, use_real_api),
                self._analyze_with_claude(query, use_real_api), 
                self._analyze_with_gpt(query, use_real_api)
            ]
            
            ai_responses = await asyncio.gather(*ai_tasks, return_exceptions=True)
            
            processed_responses = []
            for i, response in enumerate(ai_responses):
                if isinstance(response, Exception):
                    specialist_names = ["Gemini", "Claude", "GPT"]
                    log.error(f"{specialist_names[i]} analysis failed", error=str(response))
                    processed_responses.append(self._create_fallback_response(specialist_names[i], query))
                else:
                    processed_responses.append(response)
            
            print_colored("ğŸ“Š í€€í…€ ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚° ì¤‘...", "cyan")
            quantum_metrics = self._calculate_quantum_metrics(processed_responses)
            
            print_colored("ğŸ”® ìš´ëª…ì˜ ëŒ€ì¥ê°„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰...", "cyan")
            simulation_results = await self._run_destiny_simulation(query, analysis_depth)
            
            print_colored("âš¡ ì œ1ì›ì¸ í€€í…€ ì˜¤ë¼í´ ìµœì¢… ê²°ì •...", "magenta")
            final_decision = await self._make_final_decision(
                query, processed_responses, quantum_metrics, simulation_results, use_real_api
            )
            
            execution_roadmap = self._generate_execution_roadmap(final_decision, quantum_metrics)
            
            processing_time = time.time() - start_time
            
            result = {
                "query": query, "session_objective": self.session_objective,
                "timestamp": datetime.now().isoformat(), "execution_id": f"EXEC-{self.execution_count:04d}",
                "processing_time": round(processing_time, 2), "analysis_depth": analysis_depth,
                "use_real_api": use_real_api, "ai_responses": [r.to_dict() for r in processed_responses],
                "quantum_metrics": quantum_metrics.to_dict(),
                "simulation_results": [s.to_dict() for s in simulation_results[:5]],
                "final_decision": final_decision, "execution_roadmap": execution_roadmap,
                "system_info": {
                    "version": Config.VERSION,
                    "api_status": {
                        "openai": bool(Config.OPENAI_API_KEY), "anthropic": bool(Config.ANTHROPIC_API_KEY),
                        "gemini": bool(Config.GEMINI_API_KEY)
                    }
                }
            }
            
            log.info(
                "Analysis completed successfully", execution_id=result["execution_id"],
                processing_time=processing_time, quantum_metrics_valid=quantum_metrics.is_valid()
            )
            
            return result
            
        except Exception as e:
            log.exception("Comprehensive analysis failed", error=str(e))
            raise
    
    async def _analyze_with_gemini(self, query: str, use_real_api: bool) -> AIResponse:
        raw_response = await self.api_client.call_gemini(query, use_real_api)
        return AIResponse(
            specialist=AISpecialist.GEMINI, analysis_type="ë°ì´í„° ê²€ì¦ ë° ì‹œì¥ ë¶„ì„", raw_response=raw_response,
            confidence_score=random.uniform(0.88, 0.97),
            key_insights=["ê¸€ë¡œë²Œ ì‹œì¥ ê·œëª¨ ë¶„ì„", "ë°ì´í„° í’ˆì§ˆ í‰ê°€", "ì§€ì—­ë³„ ê¸°íšŒ ì‹ë³„"],
            risk_factors=["ë°ì´í„° ê²°í•", "ì§€ì—­ë³„ í¸í–¥ ê°€ëŠ¥ì„±"],
            recommendations=["ì•„ì‹œì•„ ì§€ì—­ ë°ì´í„° í™•ë³´", "ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"]
        )
    
    async def _analyze_with_claude(self, query: str, use_real_api: bool) -> AIResponse:
        raw_response = await self.api_client.call_claude(query, use_real_api)
        return AIResponse(
            specialist=AISpecialist.CLAUDE, analysis_type="ì „ëµ í”„ë ˆì„ì›Œí¬ ë° ì‹œë®¬ë ˆì´ì…˜", raw_response=raw_response,
            confidence_score=random.uniform(0.89, 0.96),
            key_insights=["PESTEL ë¶„ì„", "Porter's 5 Forces ë¶„ì„", "ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜"],
            risk_factors=["ê²½ìŸ í™˜ê²½ ê¸‰ë³€", "ê·œì œ ë³€í™” ì˜í–¥"],
            recommendations=["í”„ë¦¬ë¯¸ì—„ ì‹œì¥ ìš°ì„  ì§„ì…", "ë‹¨ê³„ì  ì‹œì¥ í™•ì¥"]
        )
    
    async def _analyze_with_gpt(self, query: str, use_real_api: bool) -> AIResponse:
        raw_response = await self.api_client.call_gpt(query, use_real_api)
        return AIResponse(
            specialist=AISpecialist.GPT, analysis_type="ì°½ì¡°ì  ëŒ€ì•ˆ ë° íŒŒê´´ì  í˜ì‹ ", raw_response=raw_response,
            confidence_score=random.uniform(0.85, 0.94),
            key_insights=["ê¸°ì¡´ ì ‘ê·¼ë²• í•œê³„ ì‹ë³„", "íŒŒê´´ì  í˜ì‹  ê¸°íšŒ ë°œê²¬", "Blue Ocean ì „ëµ"],
            risk_factors=["í˜ì‹  ì ‘ê·¼ë²•ì˜ ë¶ˆí™•ì‹¤ì„±", "ì‹œì¥ ìˆ˜ìš©ì„± ê²€ì¦ í•„ìš”"],
            recommendations=["ë©”íƒ€ë²„ìŠ¤ í”Œë«í¼ ì „ëµ", "ìŠ¤í…”ìŠ¤-ë¸”ë¦¬ì¸ -ë„ë¯¸ë„¤ì´íŠ¸ ì‹¤í–‰"]
        )
    
    def _create_fallback_response(self, specialist_name: str, query: str) -> AIResponse:
        specialist_map = {"Gemini": AISpecialist.GEMINI, "Claude": AISpecialist.CLAUDE, "GPT": AISpecialist.GPT}
        return AIResponse(
            specialist=specialist_map[specialist_name], analysis_type=f"{specialist_name} í´ë°± ë¶„ì„",
            raw_response=f"[{specialist_name} API ì˜¤ë¥˜]\nì£¼ì œ: {query}", confidence_score=0.75,
            key_insights=[], risk_factors=["API ì—°ê²° ë¶ˆì•ˆì •"], recommendations=["ì¬ë¶„ì„ ê¶Œì¥"]
        )
    
    def _calculate_quantum_metrics(self, responses: List[AIResponse]) -> QuantumMetrics:
        if not responses: return QuantumMetrics()
        avg_confidence = sum(r.confidence_score for r in responses) / len(responses)
        return QuantumMetrics(
            cmis=random.uniform(94.5, 99.2), svi=random.uniform(97.8, 99.9),
            p_alpha=random.uniform(0.05, 0.65), data_provenance=min(100.0, avg_confidence * 105),
            expert_validation=random.uniform(91.5, 98.5)
        )
    
    async def _run_destiny_simulation(self, query: str, analysis_depth: str) -> List[SimulationResult]:
        if analysis_depth == "basic":
            variables = {"market_growth": (0.2, 0.8), "competition_intensity": (0.1, 0.7)}
            iterations = 1000
        else:
            variables = {
                "market_growth": (0.1, 0.9), "innovation_index": (0.2, 1.0),
                "competition_intensity": (0.1, 0.8), "regulatory_favorability": (0.3, 0.9),
                "technology_readiness": (0.4, 1.0), "cost_efficiency": (0.3, 0.9)
            }
            iterations = 5000
        return await self.destiny_forge.run_monte_carlo_simulation(variables, iterations)
    
    async def _make_final_decision(self, query: str, responses: List[AIResponse], metrics: QuantumMetrics, simulations: List[SimulationResult], use_real_api: bool) -> Dict[str, Any]:
        if not metrics.is_valid():
            return {
                "decision": "REJECTED", "reason": "3ëŒ€ ê³µë¦¬ ë¯¸ì¶©ì¡±",
                "details": {"existence": "FAIL" if metrics.data_provenance < 95.0 else "PASS",
                            "causality": "FAIL" if metrics.svi < 98.0 else "PASS",
                            "value": "FAIL" if metrics.p_alpha <= 0 else "PASS"},
                "recommendation": "ë°ì´í„° ë³´ì™„ ë° ì „ëµ ì¬ê²€í†  í•„ìš”"
            }
        
        orchestrated_analysis = await self.api_client.orchestrate_final_decision(query, [r.raw_response for r in responses], use_real_api)
        best_simulation = simulations[0] if simulations else None
        
        return {
            "decision": "APPROVED", "confidence_level": metrics.expert_validation,
            "selected_strategy": "í•˜ì´ë¸Œë¦¬ë“œ í˜ì‹  ì „ëµ", "execution_priority": "IMMEDIATE",
            "orchestrated_analysis": orchestrated_analysis,
            "best_simulation": best_simulation.to_dict() if best_simulation else None,
        }
    
    def _generate_execution_roadmap(self, decision: Dict[str, Any], metrics: QuantumMetrics) -> Optional[Dict[str, Any]]:
        if decision.get("decision") != "APPROVED": return None
        return {"objective": self.session_objective, "timeline_months": 24, "expected_roi": 4.2}

    async def generate_comprehensive_report(self, result: Dict[str, Any]) -> str:
        lines = ["â•" * 100, f"{Config.VERSION} â€” ì¢…í•© ì°½ì¡° ë¶„ì„ ë³´ê³ ì„œ", "â•" * 100]
        metrics = result['quantum_metrics']
        lines.append(f"ğŸ“… ìƒì„± ì‹œê°: {result['timestamp']}")
        lines.append(f"ğŸ¯ ë¶„ì„ ëŒ€ìƒ: {result['query']}")
        lines.append("\nã€ğŸ“Š í€€í…€ ë©”íŠ¸ë¦­ìŠ¤ã€‘")
        lines.append(f" â€¢ SVI: {metrics['svi']:.1f} | pÎ±: {metrics['p_alpha']:.4f} | ë°ì´í„° ì‹ ë¢°ë„: {metrics['data_provenance']:.1f}%")
        lines.append(f" â€¢ 3ëŒ€ ê³µë¦¬: {'VALID âœ…' if metrics['is_valid'] else 'INVALID âŒ'}")
        
        decision = result['final_decision']
        lines.append("\nã€ğŸ‘‘ ìµœì¢… ê²°ì •ã€‘")
        lines.append(f" â€¢ ê²°ì •: {decision.get('decision')}")
        if decision.get('decision') == 'APPROVED':
            lines.append(f" â€¢ ì„ íƒ ì „ëµ: {decision.get('selected_strategy')}")
        
        lines.append("\n" + "â•" * 100)
        return "\n".join(lines)
    
    async def close(self):
        await self.api_client.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FastAPI ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ (íŒ¨ì¹˜ ì ìš© ì™„ë£Œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if FASTAPI_AVAILABLE:
    class DummyLimiter:
        def limit(self, *args, **kwargs):
            def decorator(func): return func
            return decorator
    
    limiter = Limiter(key_func=get_remote_address) if SLOWAPI_AVAILABLE and Config.ENABLE_RATELIMIT else DummyLimiter()
    
    @asynccontextmanager
    async def lifespan(app: FastAPI):
        app.state.engine = ZinoGenesisEngine(session_objective=Config.DEFAULT_SESSION_OBJECTIVE)
        log.info("ZINO-GE FastAPI application started")
        yield
        await app.state.engine.close()
        log.info("ZINO-GE FastAPI application stopped")
    
    app = FastAPI(title=Config.VERSION, version="21.0", lifespan=lifespan)
    
    app.add_middleware(
        CORSMiddleware,
        allow_origins=[o.strip() for o in Config.CORS_ALLOW_ORIGINS if o.strip()] or ["*"],
        allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
        expose_headers=["X-Request-ID", "X-Processing-Time"]
    )
    
    if SLOWAPI_AVAILABLE and Config.ENABLE_RATELIMIT:
        app.add_middleware(SlowAPIMiddleware)
        @app.exception_handler(RateLimitExceeded)
        async def rate_limit_handler(request: Request, exc: RateLimitExceeded):
            return JSONResponse(status_code=429, content={"success": False, "detail": "Too Many Requests"})

    @app.middleware("http")
    async def add_request_metadata(request: Request, call_next):
        req_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        start_time = time.time()
        response = await call_next(request)
        processing_time = time.time() - start_time
        response.headers["X-Request-ID"] = req_id
        response.headers["X-Processing-Time"] = f"{processing_time:.3f}s"
        log.info("Request completed", path=request.url.path, status_code=response.status_code, ptime=round(processing_time, 3))
        return response

    @app.get("/", tags=["Health Check"])
    async def health_check():
        return {"status": "operational", "version": Config.VERSION, "timestamp": datetime.now().isoformat()}

    @app.post("/route", tags=["Core Analysis"])
    @limiter.limit(Config.RATELIMIT_RULE)
    async def route_analysis(request: Request, x_internal_api_key: Optional[str] = Header(None)):
        if Config.ENABLE_INTERNAL_AUTH and (not x_internal_api_key or x_internal_api_key != Config.INTERNAL_API_KEY):
            raise HTTPException(status_code=401, detail="Unauthorized: Invalid API Key")
        try:
            body = await request.json()
        except json.JSONDecodeError:
            raise HTTPException(status_code=400, detail="Invalid JSON body")
        
        user_input = body.get("user_input", "")
        if not user_input.strip():
            raise HTTPException(status_code=400, detail="user_input is required")
            
        engine: ZinoGenesisEngine = request.app.state.engine
        result = await engine.execute_comprehensive_analysis(
            query=user_input,
            use_real_api=body.get("use_real_api", False),
            analysis_depth=body.get("analysis_depth", "comprehensive")
        )
        # For compatibility with pydantic response model if needed
        result['success'] = True
        result['report_md'] = await engine.generate_comprehensive_report(result)
        result['meta'] = {"timestamp": result['timestamp']}
        return result

    @app.get("/ui", response_class=HTMLResponse, tags=["User Interface"])
    async def serve_ui():
        return f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{Config.VERSION} - UI</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background: #f0f2f5; display: flex; justify-content: center; padding: 2rem; }}
        .container {{ background: white; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); width: 100%; max-width: 800px; padding: 2rem; }}
        h1 {{ font-size: 1.5rem; color: #333; }}
        textarea {{ width: 100%; padding: 0.75rem; border: 1px solid #ccc; border-radius: 4px; font-size: 1rem; margin-top: 1rem; }}
        button {{ width: 100%; padding: 0.75rem; background: #007bff; color: white; border: none; border-radius: 4px; font-size: 1rem; cursor: pointer; margin-top: 1rem; }}
        pre {{ background: #2d2d2d; color: #f1f1f1; padding: 1rem; border-radius: 4px; margin-top: 1rem; white-space: pre-wrap; word-wrap: break-word; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ {Config.VERSION}</h1>
        <textarea id="query" rows="4" placeholder="ë¶„ì„í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë ˆë…ìŠ¤í†¤ ì‚¬ì—…ì˜ ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œ ì „ëµ)"></textarea>
        <button onclick="runAnalysis()">ë¶„ì„ ì‹¤í–‰</button>
        <pre id="result">ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</pre>
    </div>
    <script>
        async function runAnalysis() {{
            const query = document.getElementById('query').value.trim();
            const resultElem = document.getElementById('result');
            if (!query) {{ resultElem.textContent = 'ì˜¤ë¥˜: ë¶„ì„í•  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.'; return; }}

            resultElem.textContent = 'ë¶„ì„ ì¤‘...';
            
            try {{
                const response = await fetch('/route', {{
                    method: 'POST',
                    headers: {{ 'Content-Type': 'application/json' }}, // [íŒ¨ì¹˜ ì ìš©] UIì—ì„œ ë‚´ë¶€ ì¸ì¦ í‚¤ ì œê±°
                    body: JSON.stringify({{ user_input: query }})
                }});
                const data = await response.json();

                if (response.ok) {{
                    // ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
                    let report = `[ë¶„ì„ ì‹œê°„: ${{data.processing_time}}ì´ˆ]\\n\\n`;
                    report += `## í€€í…€ ë©”íŠ¸ë¦­ìŠ¤\\n`;
                    report += `- SVI: ${{data.quantum_metrics.svi}}\\n- pÎ±: ${{data.quantum_metrics.p_alpha}}\\n`;
                    report += `- ë°ì´í„° ì‹ ë¢°ë„: ${{data.quantum_metrics.data_provenance}}%\\n`;
                    report += `- 3ëŒ€ ê³µë¦¬: ${{data.quantum_metrics.is_valid ? 'âœ… í†µê³¼' : 'âŒ ì‹¤íŒ¨'}}\\n\\n`;
                    report += `## ìµœì¢… ê²°ì •\\n- ê²°ì •: ${{data.final_decision.decision}}\\n`;
                    if (data.final_decision.decision === 'APPROVED') {{
                       report += `- ì „ëµ: ${{data.final_decision.selected_strategy}}`;
                    }}
                    resultElem.textContent = report;
                }} else {{
                    resultElem.textContent = `ì˜¤ë¥˜ ${{response.status}}: ${{data.detail || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}}`;
                }}
            }} catch (e) {{
                resultElem.textContent = `ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜: ${{e.message}}`;
            }}
        }}
    </script>
</body>
</html>
"""
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì§„ì…ì 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    parser = argparse.ArgumentParser(description=f"{Config.VERSION}")
    parser.add_argument('--api', action='store_true', help='ì›¹ API ì„œë²„ ëª¨ë“œë¡œ ì‹¤í–‰')
    parser.add_argument('--host', type=str, default=Config.API_HOST, help='API ì„œë²„ í˜¸ìŠ¤íŠ¸')
    parser.add_argument('--port', type=int, default=Config.API_PORT, help='API ì„œë²„ í¬íŠ¸')
    parser.add_argument('--workers', type=int, default=1, help='Uvicorn ì›Œì»¤ ìˆ˜')
    parser.add_argument('objective', nargs='*', help='(CLI ì „ìš©) ì„¸ì…˜ ëª©í‘œ ì„¤ì •')
    args = parser.parse_args()

    if args.api:
        if not FASTAPI_AVAILABLE:
            print_colored("âŒ FastAPIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install fastapi uvicorn", "red")
            sys.exit(1)
        print_colored(f"ğŸš€ {Config.VERSION} API ì„œë²„ ì‹œì‘: http://{args.host}:{args.port}", "cyan")
        # [íŒ¨ì¹˜ ì ìš©] íŒŒì¼ëª…ì— ë¬´ê´€í•œ ì•ˆì •ì ì¸ Uvicorn ì‹¤í–‰
        uvicorn.run(app, host=args.host, port=args.port, workers=args.workers, log_level="info")
    else:
        session_objective = " ".join(args.objective) if args.objective else None
        engine = ZinoGenesisEngine(session_objective=session_objective)
        cli = CLI(engine)
        cli.run()

if __name__ == "__main__":
    main()
